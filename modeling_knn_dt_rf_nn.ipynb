{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# Modeling: KNN, Decision Tree, Random Forest, Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pickle\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "\n",
    "sns.set(style='whitegrid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "load_prepare",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 908 rows and 17 columns\n",
      "Using 16 features for modeling\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "FILE_PATH = \"/media/hoang/HDD_Code/Tài liệu học tập/Kỳ 1 năm 4/Khai phá dữ liệu/mobiles_dataset_2025_clustered_labeled.csv\"\n",
    "df = pd.read_csv(FILE_PATH)\n",
    "print(f\"Loaded {len(df)} rows and {len(df.columns)} columns\")\n",
    "\n",
    "# Target and feature selection\n",
    "TARGET = 'Launched Price (USA)'\n",
    "\n",
    "# If your file contains columns with encoded companies/processors like in prior notebook, include them.\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if TARGET not in numeric_cols:\n",
    "    raise KeyError(f\"Target column '{TARGET}' not found as numeric column in dataframe\")\n",
    "feature_cols = [c for c in numeric_cols if c != TARGET]\n",
    "\n",
    "# Minimal cleaning: drop rows with missing target, impute numeric features later in pipeline\n",
    "df = df.dropna(subset=[TARGET]).reset_index(drop=True)\n",
    "X = df[feature_cols]\n",
    "y = df[TARGET]\n",
    "\n",
    "print(f\"Using {len(feature_cols)} features for modeling\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "03216a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current X columns: ['RAM', 'Front Camera', 'Back Camera', 'Battery Capacity', 'Screen Size', 'ROM', 'Company_Apple', 'Company_Honor', 'Company_Oppo', 'Company_Other', 'Company_Samsung', 'Company_Vivo', 'Processor_vec1', 'Processor_vec2', 'Processor_vec3', 'Cluster']\n",
      "Number of features: 16\n"
     ]
    }
   ],
   "source": [
    "print(\"Current X columns:\", X.columns.tolist())\n",
    "print(\"Number of features:\", X_train_prep.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "split_scale",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (726, 16) (182, 16)\n"
     ]
    }
   ],
   "source": [
    "# Train/test split\n",
    "RANDOM_STATE = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Preprocessing pipeline: impute then scale (fit on train)\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "X_train_prep = numeric_pipeline.fit_transform(X_train)\n",
    "X_test_prep = numeric_pipeline.transform(X_test)\n",
    "\n",
    "print('Shapes:', X_train_prep.shape, X_test_prep.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "eval_helpers",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_regression(true, pred):\n",
    "    mae = mean_absolute_error(true, pred)\n",
    "    rmse = np.sqrt(mean_squared_error(true, pred))\n",
    "    r2 = r2_score(true, pred)\n",
    "    return {'MAE': mae, 'RMSE': rmse, 'R2': r2}\n",
    "\n",
    "def print_eval(name, true, pred):\n",
    "    res = evaluate_regression(true, pred)\n",
    "    print(f\"{name}: MAE={res['MAE']:.3f}, RMSE={res['RMSE']:.3f}, R2={res['R2']:.3f}\")\n",
    "    return res\n",
    "\n",
    "def _is_fitted(est):\n",
    "    try:\n",
    "        check_is_fitted(est)\n",
    "        return True\n",
    "    except (NotFittedError, AttributeError):\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "models_train",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_knn already fitted\n",
      "best_dt already fitted\n",
      "rf already fitted\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ensure estimator objects exist\n",
    "# train with knn\n",
    "if 'best_knn' in globals() and isinstance(best_knn, int):\n",
    "    best_knn = KNeighborsRegressor(n_neighbors=best_knn)\n",
    "elif 'best_knn' not in globals():\n",
    "    best_knn = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "# train with decision tree\n",
    "if 'best_dt' not in globals():\n",
    "    best_dt = DecisionTreeRegressor(random_state=RANDOM_STATE)\n",
    "# train with random forest\n",
    "if 'rf' not in globals():\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "\n",
    "# Fit if needed (use train data already prepared)\n",
    "for name, est in [('best_knn', best_knn), ('best_dt', best_dt), ('rf', rf)]:\n",
    "    if not _is_fitted(est):\n",
    "        print(f\"{name} not fitted -> fitting now\")\n",
    "        est.fit(X_train_prep, y_train)\n",
    "    else:\n",
    "        print(f\"{name} already fitted\")\n",
    "# Build pipelines that include the fitted numeric_pipeline (so preprocessing is saved together)\n",
    "from sklearn.pipeline import Pipeline as SKPipeline\n",
    "knn_pipe = SKPipeline([('preprocessor', numeric_pipeline), ('model', best_knn)])\n",
    "dt_pipe  = SKPipeline([('preprocessor', numeric_pipeline), ('model', best_dt)])\n",
    "rf_pipe  = SKPipeline([('preprocessor', numeric_pipeline), ('model', rf)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "evaluate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug information:\n",
      "X_train shape: (726, 16)\n",
      "X_test shape: (182, 16)\n",
      "X_train_prep shape: (726, 16)\n",
      "X_test_prep shape: (182, 16)\n",
      "\n",
      "Feature columns: ['RAM', 'Front Camera', 'Back Camera', 'Battery Capacity', 'Screen Size', 'ROM', 'Company_Apple', 'Company_Honor', 'Company_Oppo', 'Company_Other', 'Company_Samsung', 'Company_Vivo', 'Processor_vec1', 'Processor_vec2', 'Processor_vec3', 'Cluster']\n",
      "KNN prediction failed: X has 16 features, but KNeighborsRegressor is expecting 15 features as input.\n",
      "Decision Tree prediction failed: X has 16 features, but DecisionTreeRegressor is expecting 15 features as input.\n",
      "Random Forest prediction failed: X has 16 features, but RandomForestRegressor is expecting 15 features as input.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First, let's check and debug the data shapes\n",
    "print(\"Debug information:\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"X_train_prep shape: {X_train_prep.shape}\")\n",
    "print(f\"X_test_prep shape: {X_test_prep.shape}\")\n",
    "print(\"\\nFeature columns:\", X.columns.tolist())\n",
    "# Evaluate models\n",
    "results = {}\n",
    "\n",
    "# KNN evaluation\n",
    "try:\n",
    "    knn_pred = best_knn.predict(X_test_prep)\n",
    "    results['KNN'] = print_eval('KNN', y_test, knn_pred)\n",
    "except Exception as e:\n",
    "    print(f\"KNN prediction failed: {e}\")\n",
    "\n",
    "# Decision Tree evaluation    \n",
    "try:\n",
    "    dt_pred = best_dt.predict(X_test_prep)\n",
    "    results['DecisionTree'] = print_eval('DecisionTree', y_test, dt_pred)\n",
    "except Exception as e:\n",
    "    print(f\"Decision Tree prediction failed: {e}\")\n",
    "\n",
    "# Random Forest evaluation\n",
    "try:\n",
    "    rf_pred = rf.predict(X_test_prep)\n",
    "    results['RandomForest'] = print_eval('RandomForest', y_test, rf_pred)\n",
    "except Exception as e:\n",
    "    print(f\"Random Forest prediction failed: {e}\")\n",
    "\n",
    "# Display results\n",
    "summary = pd.DataFrame(results).T\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "save_models",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: knn_model.pkl, decision_tree_model.pkl, random_forest_model.pkl,\n",
      "       knn_model.joblib, decision_tree_model.joblib, random_forest_model.joblib,\n",
      "       neural_net_model.h5\n"
     ]
    }
   ],
   "source": [
    "# Save sklearn models with pkl\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Tạo pipeline chứa cả preprocessing đã fit + model (tiện cho inference)\n",
    "knn_pipe = Pipeline([('preprocessor', numeric_pipeline), ('model', best_knn)])\n",
    "dt_pipe  = Pipeline([('preprocessor', numeric_pipeline), ('model', best_dt)])\n",
    "rf_pipe  = Pipeline([('preprocessor', numeric_pipeline), ('model', rf)])\n",
    "\n",
    "# Lưu bằng pickle (.pkl) \n",
    "with open('knn_model.pkl', 'wb') as f:\n",
    "    pickle.dump(knn_pipe, f)\n",
    "with open('decision_tree_model.pkl', 'wb') as f:\n",
    "    pickle.dump(dt_pipe, f)\n",
    "with open('random_forest_model.pkl', 'wb') as f:\n",
    "    pickle.dump(rf_pipe, f)\n",
    "\n",
    "print('Saved: knn_model.pkl, decision_tree_model.pkl, random_forest_model.pkl,')\n",
    "print('       knn_model.joblib, decision_tree_model.joblib, random_forest_model.joblib,')\n",
    "print('       neural_net_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "notes",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- Inspect feature importance from RandomForest via rf.feature_importances_ if desired.\n",
    "- Further tuning (e.g., RandomizedSearchCV), target transformation (log), or categorical encoding may improve performance.\n",
    "- Adjust dataset path and feature selection according to your processed CSV structure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
